{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import argparse\n",
    "from itertools import permutations\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dgl.data import SBMMixture\n",
    "import sbm\n",
    "import gnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "gpu=-1\n",
    "lr = 0.004\n",
    "n_communities = 5\n",
    "n_epochs = 1 \n",
    "n_features = 8 \n",
    "clip_grad_norm = 40.0 \n",
    "verbose = True\n",
    "interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_graphs = 1 \n",
    "p = 0 \n",
    "q = 18 \n",
    "n_layers = 30 \n",
    "n_nodes = 10 \n",
    "optim = 'Adamax' \n",
    "radius  = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = th.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = n_communities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = sbm.SBM(1, 10, 2, 0, 5) ## n_graphs, n_nodes, n_communities, p, q*n_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, lg, g_d, lg_d, pm_pd = training_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 5, 5, 5, 5, 7, 7, 8, 8, 8, 8, 9, 9]), tensor([5, 8, 5, 7, 9, 5, 7, 8, 8, 9, 5, 8, 0, 1, 2, 4, 1, 2, 0, 2, 3, 4, 1, 3]))\n",
      "tensor([[2.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [4.],\n",
      "        [0.],\n",
      "        [2.],\n",
      "        [4.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "print(g.all_edges())\n",
    "print(g_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 0,  0,  0,  1,  1,  1,  2,  2,  2,  3,  4,  5,  5,  5,  6,  7,  7,  7,\n",
      "         8,  8,  8,  9, 10, 10, 10, 11, 11, 11, 12, 13, 13, 14, 14, 15, 16, 16,\n",
      "        17, 17, 18, 19, 19, 20, 21, 22, 22, 23]), tensor([13, 14, 15, 19, 20, 21, 12, 14, 15, 17, 23, 12, 13, 15, 16, 18, 20, 21,\n",
      "        18, 19, 21, 22, 12, 13, 14, 18, 19, 20,  1,  3,  4,  6,  7, 11,  2,  4,\n",
      "         5,  7,  0,  5,  6,  9, 10,  2,  3,  8]))\n",
      "tensor([[3.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "print(lg.all_edges())\n",
    "print(lg_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(lg.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 4, 4, 5, 5, 5, 5, 7, 7, 8, 8, 8, 8, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "print(pm_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN([1, 8, 8, 8, 8], 2, 2).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0764,  0.1488],\n",
       "        [-0.3616, -0.1104],\n",
       "        [-0.1766,  0.0534],\n",
       "        [-0.6173,  0.0932],\n",
       "        [ 0.0764,  0.1488],\n",
       "        [ 0.3233, -0.3750],\n",
       "        [-0.6126, -0.2924],\n",
       "        [ 0.1342, -0.4919],\n",
       "        [ 0.1266, -0.9273],\n",
       "        [-0.4417, -1.1652]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_init(g)\n",
    "aggregate_init(lg)\n",
    "model(g, lg, g_d, lg_d, pm_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = 1000\n",
    "\n",
    "def pp(l):\n",
    "    for i in range(len(l)):\n",
    "        print(l[i])\n",
    "\n",
    "def printnode(g):\n",
    "    for i in range(g.number_of_nodes()):\n",
    "        print(g.nodes[i].data['id'])\n",
    "        print(g.nodes[i].data['z'])\n",
    "        print(g.nodes[i].data['t'])\n",
    "    #print(node.data['zz'])\n",
    "\n",
    "def id_to_m(edges):\n",
    "    return {'m': edges.src['id']}\n",
    "\n",
    "def m_to_t(nodes):\n",
    "    #print(nodes.__len__())\n",
    "    #print(nodes.nodes())\n",
    "    new_t_list = []\n",
    "    for i in range(nodes.__len__()):\n",
    "        cur = nodes.data['t'][i].tolist()\n",
    "        \n",
    "        if not isinstance(cur, list):\n",
    "            cur = [cur]\n",
    "            \n",
    "        new_t = cur[:cur.index(-1)]\n",
    "        \n",
    "        for m in nodes.mailbox['m'][i]:\n",
    "            m = m.tolist()\n",
    "            if isinstance(m, list):\n",
    "                if -1 in m:\n",
    "                    new_t = new_t + m[:m.index(-1)]\n",
    "                else:\n",
    "                    new_t = new_t + m\n",
    "            else:\n",
    "                new_t.append(m)\n",
    "        \n",
    "        new_t = list(set(new_t))\n",
    "        \n",
    "        if len(new_t) < ph:\n",
    "            new_t = new_t + [-1] * (ph-len(new_t))\n",
    "        \n",
    "        new_t_list.append(new_t)\n",
    "        \n",
    "    #print(th.tensor(new_t_list))\n",
    "    return {'t': th.tensor(new_t_list)}\n",
    "\n",
    "def m_to_tt(nodes):\n",
    "    #print(nodes.__len__())\n",
    "    #print(nodes.nodes())\n",
    "    new_t_list = []\n",
    "    for i in range(nodes.__len__()):\n",
    "        cur = nodes.data['t'][i].tolist()\n",
    "        \n",
    "        if not isinstance(cur, list):\n",
    "            cur = [cur]\n",
    "            \n",
    "        new_t = cur[:cur.index(-1)]\n",
    "        \n",
    "        for m in nodes.mailbox['m'][i]:\n",
    "            m = m.tolist()\n",
    "            if isinstance(m, list):\n",
    "                if -1 in m:\n",
    "                    new_t = new_t + m[:m.index(-1)]\n",
    "                else:\n",
    "                    new_t = new_t + m\n",
    "            else:\n",
    "                new_t.append(m)\n",
    "        \n",
    "        new_t = list(set(new_t))\n",
    "        \n",
    "        if len(new_t) < ph:\n",
    "            new_t = new_t + [-1] * (ph-len(new_t))\n",
    "        \n",
    "        new_t_list.append(new_t)\n",
    "        \n",
    "    #print(th.tensor(new_t_list))\n",
    "    return {'tt': th.tensor(new_t_list)}\n",
    "\n",
    "def t_to_m(edges):\n",
    "    return {'m': edges.src['t']}\n",
    "\n",
    "def aggregate_init(g):\n",
    "    for i in range(g.number_of_nodes()):\n",
    "        g.nodes[i].data['id'] = th.tensor([i])\n",
    "\n",
    "    g.ndata['t'] = th.ones([g.number_of_nodes(), ph], dtype=th.int64) * -1\n",
    "    g.ndata['tt'] = th.ones([g.number_of_nodes(), ph], dtype=th.int64) * -1\n",
    "\n",
    "    g.register_message_func(id_to_m)\n",
    "    g.register_reduce_func(m_to_t)\n",
    "\n",
    "    g.send(g.edges())\n",
    "    g.recv(g.nodes())\n",
    "\n",
    "    g.register_message_func(t_to_m)\n",
    "    g.register_reduce_func(m_to_tt)\n",
    "\n",
    "    g.send(g.edges())\n",
    "    g.recv(g.nodes())\n",
    "\n",
    "class GNNModule(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, radius):\n",
    "        super().__init__()\n",
    "        self.in_feats = in_feats\n",
    "        self.out_feats = out_feats\n",
    "        self.radius = radius\n",
    "\n",
    "        new_linear = lambda: nn.Linear(in_feats, out_feats)\n",
    "        new_linear_list = lambda: nn.ModuleList([new_linear() for i in range(radius)])\n",
    "\n",
    "        self.theta_x, self.theta_deg, self.theta_y = \\\n",
    "            new_linear(), new_linear(), new_linear()\n",
    "        self.theta_list = new_linear_list()\n",
    "\n",
    "        self.gamma_y, self.gamma_deg, self.gamma_x = \\\n",
    "            new_linear(), new_linear(), new_linear()\n",
    "        self.gamma_list = new_linear_list()\n",
    "\n",
    "        self.bn_x = nn.BatchNorm1d(out_feats)\n",
    "        self.bn_y = nn.BatchNorm1d(out_feats)\n",
    "\n",
    "    \n",
    "    def t_to_feature(self, g):\n",
    "        #print(g.ndata['z'])\n",
    "        for i in range(g.number_of_nodes()):\n",
    "            ind = g.nodes[i].data['t'][0].tolist()\n",
    "            \n",
    "            if ind == [0] * ph or ind[0] == -1:\n",
    "                ind = [i]\n",
    "            elif -1 in ind:\n",
    "                ind = ind[:ind.index(-1)]\n",
    "                \n",
    "            ind = th.tensor(ind)\n",
    "            #print(\"================  t_to_feature ============\")\n",
    "            #print(g.ndata['z'])\n",
    "            #print(ind)\n",
    "            #print((g.nodes[ind].data['z']))\n",
    "            #print(th.sum(g.nodes[ind].data['z'], dim=0))\n",
    "            #print(th.tensor([th.sum(g.nodes[ind].data['z'], dim=0).tolist()]))\n",
    "            if self.in_feats == 1:\n",
    "                g.nodes[i].data['zz'] = th.sum(g.nodes[ind].data['z'], dim=0)\n",
    "            else:\n",
    "                g.nodes[i].data['zz'] = th.tensor([th.sum(g.nodes[ind].data['z'], dim=0).tolist()])\n",
    "        \n",
    "            \n",
    "    def tt_to_feature(self, g):\n",
    "        #print(g.ndata['z'])\n",
    "        for i in range(g.number_of_nodes()):\n",
    "            ind = g.nodes[i].data['tt'][0].tolist()\n",
    "            \n",
    "            if ind == [0] * ph or ind[0] == -1:\n",
    "                ind = [i]\n",
    "            elif -1 in ind:\n",
    "                ind = ind[:ind.index(-1)]\n",
    "                \n",
    "            ind = th.tensor(ind)\n",
    "            #print(\"================  t_to_feature ============\")\n",
    "            #print(g.ndata['z'])\n",
    "            #print(ind)\n",
    "            #print((g.nodes[ind].data['z']))\n",
    "            #print(th.sum(g.nodes[ind].data['z'], dim=0))\n",
    "            #print(th.tensor([th.sum(g.nodes[ind].data['z'], dim=0).tolist()]))\n",
    "            if self.in_feats == 1:\n",
    "                g.nodes[i].data['zz'] = th.sum(g.nodes[ind].data['z'], dim=0)\n",
    "            else:\n",
    "                g.nodes[i].data['zz'] = th.tensor([th.sum(g.nodes[ind].data['z'], dim=0).tolist()])\n",
    "\n",
    "    def aggregate(self, g, z):\n",
    "        ###g.register_message_func(id_to_m)\n",
    "        \n",
    "        ###g.register_reduce_func(m_to_t)\n",
    "        \n",
    "        z_list = []\n",
    "        g.set_n_repr({'z' : z})\n",
    "        \n",
    "        ###self.aggregate_init(g)\n",
    "        #g.update_all(fn.copy_src(src='id', out='m'), fn.sum(msg='m', out='z'))\n",
    "        ###g.send(g.edges())\n",
    "        \n",
    "        ###g.recv(g.nodes())\n",
    "        \n",
    "        ###g.register_message_func(t_to_m)\n",
    "        \n",
    "        self.t_to_feature(g)\n",
    "        \n",
    "        if self.in_feats == 1:\n",
    "            z = th.tensor([[b] for b in g.ndata.pop('zz').tolist()])\n",
    "        else:\n",
    "            z = g.ndata.pop('zz')\n",
    "        \n",
    "        z_list.append(z)\n",
    "        '''\n",
    "        for i in range(self.radius-1):\n",
    "           for j in range(2 ** i):\n",
    "                g.send(g.edges())\n",
    "                g.recv(g.nodes())\n",
    "                #g.update_all(fn.copy_src(src='z', out='m'), fn.sum(msg='m', out='z'))\n",
    "        '''    \n",
    "        self.tt_to_feature(g)\n",
    "            \n",
    "        if self.in_feats == 1:\n",
    "            z = th.tensor([[b] for b in g.ndata.pop('zz').tolist()])\n",
    "        else:\n",
    "            z = g.ndata.pop('zz')\n",
    "            \n",
    "            #print('============== z ==============')\n",
    "            #print(z)\n",
    "            \n",
    "        z_list.append(z)\n",
    "        \n",
    "        #print('==============. g  =========')\n",
    "        #printnode(g)\n",
    "        #print('==============. zlist  =========')\n",
    "        #print(z_list)\n",
    "        return z_list\n",
    "\n",
    "    def forward(self, g, lg, x, y, deg_g, deg_lg, pm_pd):\n",
    "        pmpd_x = F.embedding(pm_pd, x)\n",
    "        \n",
    "        ##print(pmpd_x)\n",
    "        \n",
    "        a = self.aggregate(g,x)\n",
    "        \n",
    "        ##print(a)\n",
    "        \n",
    "        sum_x = sum(theta(z) for theta, z in zip(self.theta_list, a))\n",
    "\n",
    "        g.set_e_repr({'y' : y})\n",
    "        g.update_all(fn.copy_edge(edge='y', out='m'), fn.sum('m', 'pmpd_y'))\n",
    "        pmpd_y = g.pop_n_repr('pmpd_y')\n",
    "\n",
    "        x = self.theta_x(x) + self.theta_deg(deg_g * x) + sum_x + self.theta_y(pmpd_y)\n",
    "        n = self.out_feats // 2\n",
    "        x = th.cat([x[:, :n], F.relu(x[:, n:])], 1)\n",
    "        x = self.bn_x(x)\n",
    "\n",
    "        sum_y = sum(gamma(z) for gamma, z in zip(self.gamma_list, self.aggregate(lg, y)))\n",
    "\n",
    "        y = self.gamma_y(y) + self.gamma_deg(deg_lg * y) + sum_y + self.gamma_x(pmpd_x)\n",
    "        y = th.cat([y[:, :n], F.relu(y[:, n:])], 1)\n",
    "        y = self.bn_y(y)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, feats, radius, n_classes):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        g : networkx.DiGraph\n",
    "        \"\"\"\n",
    "        super(GNN, self).__init__()\n",
    "        self.linear = nn.Linear(feats[-1], n_classes)\n",
    "        self.module_list = nn.ModuleList([GNNModule(m, n, radius)\n",
    "                                          for m, n in zip(feats[:-1], feats[1:])])\n",
    "\n",
    "    def forward(self, g, lg, deg_g, deg_lg, pm_pd):\n",
    "        x, y = deg_g, deg_lg\n",
    "        for module in self.module_list:\n",
    "            x, y = module(g, lg, x, y, deg_g, deg_lg, pm_pd)\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##training_dataset = sbm.SBM(args.n_graphs, args.n_nodes, K, p, q)\n",
    "##training_dataset = SBMMixture(args.n_graphs, args.n_nodes, K)\n",
    "##training_loader = DataLoader(training_dataset, args.batch_size, collate_fn=training_dataset.collate_fn, drop_last=True)\n",
    "\n",
    "ones = th.ones(args.n_nodes // K)\n",
    "y_list = [th.cat([x * ones for x in p]).long().to(dev)\n",
    "          for p in permutations(range(K))]\n",
    "\n",
    "##feats = [1] + [args.n_features] * args.n_layers + [K]\n",
    "feats = [1] + [args.n_features] * args.n_layers\n",
    "model = gnn.GNN(feats, args.radius, K).to(dev)\n",
    "optimizer = getattr(optim, args.optim)(model.parameters(), lr=args.lr)\n",
    "\n",
    "\n",
    "def compute_overlap(z_list):\n",
    "    ybar_list = [th.max(z, 1)[1] for z in z_list]\n",
    "    overlap_list = []\n",
    "    for y_bar in ybar_list:\n",
    "        accuracy = max(th.sum(y_bar == y).item()\n",
    "                       for y in y_list) / args.n_nodes\n",
    "        overlap = (accuracy - 1 / K) / (1 - 1 / K)\n",
    "        overlap_list.append(overlap)\n",
    "    return sum(overlap_list) / len(overlap_list)\n",
    "\n",
    "\n",
    "def from_np(f, *args):\n",
    "    def wrap(*args):\n",
    "        new = [th.from_numpy(x) if isinstance(\n",
    "            x, np.ndarray) else x for x in args]\n",
    "        return f(*new)\n",
    "    return wrap\n",
    "\n",
    "\n",
    "@from_np\n",
    "def step(i, j, g, lg, deg_g, deg_lg, pm_pd):\n",
    "    \"\"\" One step of training. \"\"\"\n",
    "    deg_g = deg_g.to(dev)\n",
    "    deg_lg = deg_lg.to(dev)\n",
    "    pm_pd = pm_pd.to(dev)\n",
    "    t0 = time.time()\n",
    "    z = model(g, lg, deg_g, deg_lg, pm_pd)\n",
    "    t_forward = time.time() - t0\n",
    "\n",
    "    z_list = th.chunk(z, args.batch_size, 0)\n",
    "    loss = sum(min(F.cross_entropy(z, y) for y in y_list)\n",
    "               for z in z_list) / args.batch_size\n",
    "    overlap = compute_overlap(z_list)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    t0 = time.time()\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), args.clip_grad_norm)\n",
    "    t_backward = time.time() - t0\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss, overlap, t_forward, t_backward\n",
    "\n",
    "\n",
    "@from_np\n",
    "def inference(g, lg, deg_g, deg_lg, pm_pd):\n",
    "    deg_g = deg_g.to(dev)\n",
    "    deg_lg = deg_lg.to(dev)\n",
    "    pm_pd = pm_pd.to(dev)\n",
    "\n",
    "    z = model(g, lg, deg_g, deg_lg, pm_pd)\n",
    "\n",
    "    return z\n",
    "\n",
    "\n",
    "def test():\n",
    "    p_list = [6, 5.5, 5, 4.5, 1.5, 1, 0.5, 0]\n",
    "    q_list = [0, 0.5, 1, 1.5, 4.5, 5, 5.5, 6]\n",
    "    N = 1\n",
    "    overlap_list = []\n",
    "    for p, q in zip(p_list, q_list):\n",
    "        dataset = SBMMixture(N, args.n_nodes, K, pq=[[p, q]] * N)\n",
    "        loader = DataLoader(dataset, N, collate_fn=dataset.collate_fn)\n",
    "        g, lg, deg_g, deg_lg, pm_pd = next(iter(loader))\n",
    "        z = inference(g, lg, deg_g, deg_lg, pm_pd)\n",
    "        overlap_list.append(compute_overlap(th.chunk(z, N, 0)))\n",
    "    return overlap_list\n",
    "\n",
    "\n",
    "n_iterations = args.n_graphs // args.batch_size\n",
    "for i in range(args.n_epochs):\n",
    "    total_loss, total_overlap, s_forward, s_backward = 0, 0, 0, 0\n",
    "# for j, [g, lg, deg_g, deg_lg, pm_pd] in enumerate(training_loader):\n",
    "    for j in range(args.n_graphs):\n",
    "        g, lg, deg_g, deg_lg, pm_pd = sbm.SBM(\n",
    "            1, args.n_nodes, K, p, q).__getitem__(0)\n",
    "\n",
    "        loss, overlap, t_forward, t_backward = step(\n",
    "            i, j, g, lg, deg_g, deg_lg, pm_pd)\n",
    "\n",
    "        total_loss += loss\n",
    "        total_overlap += overlap\n",
    "        s_forward += t_forward\n",
    "        s_backward += t_backward\n",
    "\n",
    "        if j % args.interval == 0:\n",
    "\n",
    "            if j > 0:\n",
    "                print('=================== interval %d | loss %0.3f | overlap %.3f ==================='\n",
    "                      % (j, interval_loss/args.interval, interval_overlap/args.interval))\n",
    "\n",
    "            interval_loss = 0\n",
    "            interval_overlap = 0\n",
    "\n",
    "        interval_loss += loss\n",
    "        interval_overlap += overlap\n",
    "\n",
    "        epoch = '0' * (len(str(args.n_epochs)) - len(str(i)))\n",
    "        iteration = '0' * (len(str(n_iterations)) - len(str(j)))\n",
    "        if args.verbose:\n",
    "            print(dt.now(), '[epoch %s%d iteration %s%d]loss %.3f | overlap %.3f'\n",
    "                  % (epoch, i, iteration, j, loss, overlap))\n",
    "\n",
    "    epoch = '0' * (len(str(args.n_epochs)) - len(str(i)))\n",
    "    loss = total_loss / (j + 1)\n",
    "    overlap = total_overlap / (j + 1)\n",
    "    t_forward = s_forward / (j + 1)\n",
    "    t_backward = s_backward / (j + 1)\n",
    "    print('[epoch %s%d]loss %.3f | overlap %.3f | forward time %.3fs | backward time %.3fs'\n",
    "          % (epoch, i, loss, overlap, t_forward, t_backward))\n",
    "\n",
    "    overlap_list = test()\n",
    "    overlap_str = ' - '.join(['%.3f' % overlap for overlap in overlap_list])\n",
    "    print('[epoch %s%d]overlap: %s' % (epoch, i, overlap_str))\n",
    "\n",
    "th.save(model.state_dict(), args.save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "725px",
    "left": "1163px",
    "right": "42px",
    "top": "85px",
    "width": "475px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
